{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_defs as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2b_files = glob(f'{ed.dump_loc}/*shared_open_data_b2b_order*')\n",
    "logistic_files = glob(f'{ed.dump_loc}/*shared_open_data_logistics_order*')\n",
    "retail_files = glob(f'{ed.dump_loc}/*nhm_order_fulfillment_subset_v1*')\n",
    "voucher_files = glob(f'{ed.dump_loc}/*shared_open_data_gift_voucher_order*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_tbl = pd.read_parquet(ed.script_loc+\"pc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ETL_Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await ETL_Loader.insert_into_pincode(ETL_Loader.pg_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalogue the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistics_files = glob(f'{ed.raw_files}/*shared_open_data_logistics_order*')\n",
    "b2b_files = glob(f'{ed.raw_files}/*shared_open_data_b2b_order*')\n",
    "b2c_files = glob(f'{ed.raw_files}/*nhm_order_fulfillment_subset_v1*')    \n",
    "voucher_files = glob(f'{ed.raw_files}/*shared_open_data_gift_voucher_order*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import env_defs as ed\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_tbl = pd.read_parquet(ed.script_loc+\"pc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_tbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistics_files = glob(f'{ed.raw_files}/*shared_open_data_logistics_order*')\n",
    "b2b_files = glob(f'{ed.raw_files}/*shared_open_data_b2b_order*')\n",
    "b2c_files = glob(f'{ed.raw_files}/*nhm_order_fulfillment_subset_v1*')    \n",
    "voucher_files = glob(f'{ed.raw_files}/*shared_open_data_gift_voucher_order*')\n",
    "\n",
    "val_dict = {\"logistics\":logistics_files, \n",
    "            \"retail_b2b\":b2b_files, \n",
    "            \"retail_b2c\":b2c_files, \n",
    "            \"voucher\":voucher_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logistics(tgt_file: str, file_category:str):\n",
    "    \"\"\"\n",
    "    tgt_file: The File to process in Parquet format.\n",
    "    Pincode file Dataframe will be a global variable.\n",
    "    file_dump_loc: Where it should be written. \n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        tgt_df = pd.read_parquet(tgt_file)\n",
    "    except:\n",
    "        print(\"Parquet files only.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    dt_val = tgt_file.split(\"query_result_\")[1].split(\"_\")[0]\n",
    "    row_count = tgt_df.shape[0]\n",
    "    \n",
    "    if row_count < 1:\n",
    "        print(f\"Empty Dataframe {tgt_df}\")\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Proceeding with {tgt_file}\")\n",
    "    \n",
    "    print(\"Truncating the Pincode columns\")\n",
    "    # tgt_df[\"pick_up_pincode\"] = tgt_df[\"pick_up_pincode\"].str.strip()\n",
    "    # tgt_df[\"delivery_pincode\"] = tgt_df[\"delivery_pincode\"].str.strip()\n",
    "    \n",
    "    # tgt_df[\"pick_up_pincode\"] = tgt_df[\"pick_up_pincode\"].str.split(\".\",expand=True)[0]\n",
    "    # tgt_df[\"delivery_pincode\"] = tgt_df[\"delivery_pincode\"].str.split(\".\",expand=True)[0]\n",
    "    \n",
    "    tgt_df[\"pick_up_pincode\"] = tgt_df[\"pick_up_pincode\"].astype(float).astype(int).astype(str)\n",
    "    tgt_df[\"delivery_pincode\"] = tgt_df[\"delivery_pincode\"].astype(float).astype(int).astype(str)\n",
    "\n",
    "    \n",
    "    print(\"Populating Delivery Stats.\")\n",
    "    final_df = tgt_df.merge(pc_tbl, left_on=\"delivery_pincode\", \n",
    "                                    right_on=\"Pincode\", how=\"left\").drop(columns=[\n",
    "                                        \"Pincode\",\"delivery_district\",\"delivery_state\",\"delivery_state_code\"]).rename(\n",
    "                                            columns={\"Statename\":\"delivery_state\",\n",
    "                                                     \"Districtname\":\"delivery_district\", \n",
    "                                                     \"Statecode\":\"delivery_state_code\"})\n",
    "    print(\"Populating Seller Stats.\")\n",
    "    final_df = final_df.merge(pc_tbl, left_on=\"pick_up_pincode\", \n",
    "                                              right_on=\"Pincode\", how=\"left\").drop(columns=[\n",
    "                                                  \"Pincode\",\"seller_district\",\"seller_state\",\"seller_state_code\"]).rename(\n",
    "                                                      columns={\"Statename\":\"seller_state\",\n",
    "                                                               \"Districtname\":\"seller_district\", \n",
    "                                                               \"Statecode\":\"seller_state_code\"})\n",
    "    if final_df.shape[0] == row_count:\n",
    "        print(final_df.shape[0], row_count)\n",
    "        print(\"Rows Match, proceeding.\\n\")\n",
    "        final_df.to_parquet(f\"{ed.processed_files}_{dt_val}_{file_category}.parquet\")\n",
    "    else:\n",
    "        print(\"Row Mismatch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_df = pd.read_parquet(logistics_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_df[[\"transaction_id\", \"fulfillment_status\", \"domain\",\n",
    "        \"network_retail_order_id\", \"shipment_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_df[[\"transaction_id\", \"network_retail_order_id\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
